# MedLaunch RAG Project

A Retrieval-Augmented Generation (RAG) system designed to process medical PDFs and enable intelligent document querying using embeddings and language models.

## Project Overview

This project implements a complete RAG pipeline that:
- Extracts and processes PDF documents
- Generates embeddings for document chunks
- Builds searchable indices
- Enables natural language querying of document content

## Features

- **PDF Processing**: Extracts text from PDF files with intelligent chunking
- **Embedding Generation**: Creates vector embeddings for semantic search
- **Index Management**: Maintains embeddings index for fast retrieval
- **Query Handler**: Processes user queries and retrieves relevant documents

## Project Structure

```
MedlaunchRAGProject/
├── embedding_generator.py      # Generates embeddings from text chunks
├── pdf_processor.py            # Processes and extracts text from PDFs
├── query_handler.py            # Handles user queries and retrieval
├── embeddings_index.json       # Stores generated embeddings
├── requirements.txt            # Python dependencies
├── README.md                   # Project documentation
├── .gitignore                  # Git ignore rules
├── files/                      # Input PDF files directory
└── myenv/                      # Python virtual environment
```

## Installation

### Prerequisites

- Python 3.11
- pip package manager

### Setup to run locally

1. **Create and activate virtual environment**:
   ```bash
   python3 -m venv myenv
   source myenv/bin/activate
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

## Usage

### 1. Process PDF Documents

Process PDF files from the `files/` directory:

```bash
python pdf_processor.py
```

This generates text chunks stored in the `chunks/` directory.

### 2. Generate Embeddings

Create embeddings for processed text chunks:

```bash
python embedding_generator.py
```

Embeddings are saved to `embeddings_index.json`.

### 3. Query Documents

Search and retrieve information from processed documents:

```bash
python query_handler.py
```

## Continuous Interactions (CLI)

For continuous interactions with the AWS Lambda `query_handler`, use `local_cli.py` (or your CLI script). This tool will iteratively send requests to your Lambda function and display responses, enabling interactive querying from your terminal.

Example usage:
```bash
python local_cli.py
```
This will prompt for queries, send them to the Lambda, and print the results in real time.

## Requirements

Key dependencies include:
- **pdfplumber**: PDF text extraction
- **langchain**: LLM framework and text splitting
- **boto3**: AWS integration
- **httpx**: HTTP client for API calls
- **pydantic**: Data validation

See `requirements.txt` for complete list.

## Configuration

All configuration values are now centralized in `config.py`.
- **No hardcoded values**: S3 bucket names, model IDs, chunk sizes, embedding parameters, and thresholds are all set in `config.py`.
- To change any behavior (e.g., chunk size, embedding model, AWS region, LLM temperature), update the relevant value in `config.py`.
- Example config values:
  - `BUCKET_NAME`, `AWS_REGION`, `EMBEDDING_MODEL`, `LLM_MODEL`, `PDF_CHUNK_SIZE`, `TOP_K_RESULTS`, etc.

## Query Handler (query_handler.py)

- Loads the embeddings index from S3 **once** and caches it in memory for fast repeated queries.
- Uses the Titan Embeddings and Claude LLM models, both initialized from config values.
- Supports two query modes:
  - **Citation Mode**: Returns the exact text for a specific chapter (e.g., "Show me chapter MM.1").
  - **Question Mode**: Uses RAG to answer questions based on retrieved context chunks.
- Confidence scoring is based on similarity thresholds from config.
- All S3, model, and search parameters are now configurable via `config.py`.

## Output

- **Text Chunks**: Stored in `chunks/` directory
- **Embeddings Index**: Stored in `embeddings_index.json` (and in S3)
- **Query Results**: Returned in real-time from `query_handler.py` (with confidence and citations)

## Notes

- Ensure PDF files are placed in the `files/` directory before processing
- The virtual environment (`myenv/`) should not be committed to git
- All generated chunks and indices can be regenerated by rerunning the scripts



## Contributing

Guidelines for contributing to this project.
